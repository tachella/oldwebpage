<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>neural networks &#8211; Julián Tachella</title>
	<atom:link href="https://tachella.github.io/category/neural-networks/feed/" rel="self" type="application/rss+xml" />
	<link>http://tachella.github.io/</link>
	<description></description>
	<lastBuildDate>Tue, 01 Sep 2020 17:44:19 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.5</generator>

<image>
	<url>https://tachella.github.io/wp-content/uploads/2019/10/cropped-me-1-150x150.jpg</url>
	<title>neural networks &#8211; Julián Tachella</title>
	<link>http://tachella.github.io/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>The neural tangent denoiser</title>
		<link>https://tachella.github.io/2020/09/01/the-neural-tangent-denoiser/</link>
		
		<dc:creator><![CDATA[Julián]]></dc:creator>
		<pubDate>Tue, 01 Sep 2020 13:31:04 +0000</pubDate>
				<category><![CDATA[neural networks]]></category>
		<guid isPermaLink="false">https://tachella.github.io/?p=344</guid>

					<description><![CDATA[Authors: J. Tachella, J. Tang and Mike Davies Full paper: https://arxiv.org/abs/2006.02379 Online codes: https://gitlab.com/Tachella/neural_tangent_denoiser Convolutional neural networks (CNNs) are a well-established tool for solving computational imaging problems.  It has been recently shown that, despite being highly overparameterized (more weights than pixels), networks trained with a single corrupted image can still perform as well as fully trained&#46;&#46;&#46;]]></description>
										<content:encoded><![CDATA[<p><strong>Authors:</strong> J. Tachella, J. Tang and Mike Davies</p>
<p><strong>Full paper: </strong><a href="https://arxiv.org/abs/2006.02379">https://arxiv.org/abs/2006.02379</a></p>
<p><strong>Online codes: </strong><a href="https://gitlab.com/Tachella/neural_tangent_denoiser">https://gitlab.com/Tachella/neural_tangent_denoiser</a></p>
<p>Convolutional neural networks (CNNs) are a well-established tool for solving computational imaging problems.  It has been recently shown that, despite being highly overparameterized (more weights than pixels), networks trained with a single corrupted image can still perform as well as fully trained networks (<em>a.k.a. <a href="https://dmitryulyanov.github.io/deep_image_prior">the deep image prior</a></em>).  These results highlight that <strong>CNNs posses a very powerful learning bias towards natural images</strong>, which explains their great success in recent years. Multiple intriguing question arise:</p>
<ol>
<li>What is the learning bias?</li>
<li>Are neural networks performing something similar to other existing tools in signal processing?</li>
<li>Is the existing theory able to explain this phenomenon?</li>
</ol>
<p>In this paper, we make a first step towards answering these questions, using recent theoretical insights of infinitely wide networks (<em>a.k.a. <a href="https://arxiv.org/abs/1806.07572">the neural tangent kernel</a></em>), elucidating formal links between CNNs and well-known non-local patch denoisers, such as non-local means.</p>
<p><img loading="lazy" class="size-large wp-image-349 aligncenter" src="https://tachella.github.io/wp-content/uploads/2020/09/non_local-1024x200.png" alt="" width="740" height="145" srcset="https://tachella.github.io/wp-content/uploads/2020/09/non_local-1024x200.png 1024w, https://tachella.github.io/wp-content/uploads/2020/09/non_local-300x59.png 300w, https://tachella.github.io/wp-content/uploads/2020/09/non_local-768x150.png 768w, https://tachella.github.io/wp-content/uploads/2020/09/non_local-1536x300.png 1536w, https://tachella.github.io/wp-content/uploads/2020/09/non_local-520x102.png 520w, https://tachella.github.io/wp-content/uploads/2020/09/non_local-940x183.png 940w, https://tachella.github.io/wp-content/uploads/2020/09/non_local.png 1793w" sizes="(max-width: 740px) 100vw, 740px" /></p>
<p>Non-local means uses the following non-local similarity function:</p>
<p class="ql-center-displayed-equation" style="line-height: 22px;"><span class="ql-right-eqno"> &nbsp; </span><span class="ql-left-eqno"> &nbsp; </span><img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-8da5ad2a4f7f312ce398933f1d67e66c_l3.png" height="22" width="245" class="ql-img-displayed-equation quicklatex-auto-format" alt="&#92;&#91;&#107;&#40;&#121;&#95;&#105;&#44;&#32;&#121;&#95;&#106;&#41;&#32;&#61;&#32;&#92;&#101;&#120;&#112;&#40;&#45;&#124;&#124;&#121;&#95;&#105;&#45;&#121;&#95;&#106;&#124;&#124;&#94;&#50;&#47;&#92;&#115;&#105;&#103;&#109;&#97;&#94;&#50;&#41;&#92;&#93;" title="Rendered by QuickLaTeX.com"/></p>
<p>where <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-bb3c186e5c65fcd066bb23dec8f4e48a_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#121;&#95;&#105;" title="Rendered by QuickLaTeX.com" height="12" width="14" style="vertical-align: -4px;"/> and <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-96175939671012225c6ebb5b4b67a92d_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#121;&#95;&#106;" title="Rendered by QuickLaTeX.com" height="14" width="15" style="vertical-align: -6px;"/> are small image patches (e.g. <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-101f8b3f33bf66bfc25df43f96acd9fa_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#53;&#92;&#116;&#105;&#109;&#101;&#115;&#32;&#53;" title="Rendered by QuickLaTeX.com" height="13" width="39" style="vertical-align: 0px;"/> pixels) around the pixels <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-695d9d59bd04859c6c99e7feb11daab6_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#105;" title="Rendered by QuickLaTeX.com" height="12" width="6" style="vertical-align: 0px;"/> and <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-43c82d5bb00a7568d935a12e3bd969dd_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#106;" title="Rendered by QuickLaTeX.com" height="16" width="9" style="vertical-align: -4px;"/>. The filter matrix <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-4caed22919a1780df1b6310b338b904e_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#87;" title="Rendered by QuickLaTeX.com" height="12" width="19" style="vertical-align: 0px;"/> is constructed as <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-4f312419c8b16c4d57ea5a27efdab8d6_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#87;&#32;&#61;&#32;&#92;&#116;&#101;&#120;&#116;&#123;&#100;&#105;&#97;&#103;&#125;&#40;&#92;&#102;&#114;&#97;&#99;&#123;&#49;&#125;&#123;&#49;&#94;&#84;&#75;&#125;&#41;&#32;&#75;" title="Rendered by QuickLaTeX.com" height="23" width="138" style="vertical-align: -7px;"/> and the simplest denoising procedure consists of applying <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-4caed22919a1780df1b6310b338b904e_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#87;" title="Rendered by QuickLaTeX.com" height="12" width="19" style="vertical-align: 0px;"/> to the (vectorized) noisy image <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-0af556714940c351c933bba8cf840796_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#121;" title="Rendered by QuickLaTeX.com" height="12" width="9" style="vertical-align: -4px;"/>, that is <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-6f80189a4cb464104d4c7fa32992ac55_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#92;&#104;&#97;&#116;&#123;&#122;&#125;&#61;&#87;&#32;&#121;" title="Rendered by QuickLaTeX.com" height="16" width="61" style="vertical-align: -4px;"/>. There are more sophisticated procedures such as twicing, where the filtering matrix is applied iteratively to the residual:</p>
<p class="ql-center-displayed-equation" style="line-height: 22px;"><span class="ql-right-eqno"> &nbsp; </span><span class="ql-left-eqno"> &nbsp; </span><img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-4e73c94ecbd4126fa7c4e2469453c264_l3.png" height="22" width="178" class="ql-img-displayed-equation quicklatex-auto-format" alt="&#92;&#91;&#122;&#94;&#123;&#107;&#43;&#49;&#125;&#32;&#61;&#32;&#122;&#94;&#123;&#107;&#125;&#32;&#43;&#32;&#87;&#40;&#121;&#45;&#122;&#94;&#123;&#107;&#125;&#41;&#92;&#93;" title="Rendered by QuickLaTeX.com"/></p>
<p> This procedure trades bias (over-smooth estimates) for variance (noisy estimates), and is stopped when a good balance is achieved. <strong>How does this relate to a convolutional neural network trained with a single image?</strong> It turns out that, as the network&#8217;s width increases, standard gradient descent optimization of the squared <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-dd583ea6096b89172262dd03722f6731_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#92;&#101;&#108;&#108;&#95;&#50;" title="Rendered by QuickLaTeX.com" height="15" width="14" style="vertical-align: -3px;"/> loss follows the twicing process, with a (fixed!) filter matrix <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-74a348aef7edf0abf99651a0b53e54ad_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#87;&#61;&#75;" title="Rendered by QuickLaTeX.com" height="12" width="59" style="vertical-align: 0px;"/> where the<strong> pixel affinity function is available in closed form and only depends on the architecture of the network! </strong>For example, a simple single-hidden layer network with a filter of <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-d30f9396f90049805a7462b39118fd1c_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#107;&#92;&#116;&#105;&#109;&#101;&#115;&#32;&#107;" title="Rendered by QuickLaTeX.com" height="12" width="40" style="vertical-align: 0px;"/> pixels, corresponds to a non-local similarity function</p>
<p class="ql-center-displayed-equation" style="line-height: 38px;"><span class="ql-right-eqno"> &nbsp; </span><span class="ql-left-eqno"> &nbsp; </span><img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-04987d3a6ffb3a929cbd7ecd46e90366_l3.png" height="38" width="325" class="ql-img-displayed-equation quicklatex-auto-format" alt="&#92;&#91;&#107;&#40;&#121;&#95;&#105;&#44;&#32;&#121;&#95;&#106;&#41;&#32;&#61;&#32;&#92;&#102;&#114;&#97;&#99;&#123;&#124;&#124;&#121;&#95;&#105;&#124;&#124;&#32;&#124;&#124;&#121;&#95;&#106;&#124;&#124;&#125;&#123;&#92;&#112;&#105;&#125;&#32;&#40;&#92;&#115;&#105;&#110;&#92;&#112;&#104;&#105;&#43;&#40;&#92;&#112;&#105;&#45;&#92;&#112;&#104;&#105;&#41;&#92;&#99;&#111;&#115;&#92;&#112;&#104;&#105;&#41;&#92;&#93;" title="Rendered by QuickLaTeX.com"/></p>
<p> where <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-5b2be26c0c1341f54b29baddda771346_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#92;&#112;&#104;&#105;" title="Rendered by QuickLaTeX.com" height="16" width="11" style="vertical-align: -4px;"/> is the angle between patches <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-bb3c186e5c65fcd066bb23dec8f4e48a_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#121;&#95;&#105;" title="Rendered by QuickLaTeX.com" height="12" width="14" style="vertical-align: -4px;"/> and <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-96175939671012225c6ebb5b4b67a92d_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#121;&#95;&#106;" title="Rendered by QuickLaTeX.com" height="14" width="15" style="vertical-align: -6px;"/> of <img loading="lazy" src="https://tachella.github.io/wp-content/ql-cache/quicklatex.com-d30f9396f90049805a7462b39118fd1c_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#107;&#92;&#116;&#105;&#109;&#101;&#115;&#32;&#107;" title="Rendered by QuickLaTeX.com" height="12" width="40" style="vertical-align: 0px;"/> pixels each. Hence, we can compute the implicit filter in closed-form, without need to train a very large network!</p>
<p>Our analysis reveals that a neural network that, while the NTK theory accurately predicts the filter associated with networks trained using standard gradient descent, it falls short to explain the behavior of networks trained using the popular Adam optimizer. The latter achieves a larger change of weights in hidden layers, adapting the non-local filtering function during training. We evaluate our findings via extensive image denoising experiments. Please see the paper for more details!</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
