<!DOCTYPE html>
<html class="no-js" lang="en-US">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	
	
	
	<title>Equivariant imaging: Learning beyond the range space &ndash; Juli&aacute;n Tachella</title>

<script>
MathJax = {
  tex: {
    inlineMath: [['$','$'],['\\(','\\)']], 
    processEscapes: true
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore|editor-rich-text'
  }
};

</script>
<script>document.documentElement.className = document.documentElement.className.replace("no-js","js");</script>
<link rel="dns-prefetch" href="//cdn.jsdelivr.net">
<link rel="dns-prefetch" href="//fonts.googleapis.com">

<link rel="alternate" type="application/rss+xml" title="Juli&aacute;n Tachella &raquo; Feed" href="https://tachella.github.io/feed/">
<link rel="alternate" type="application/rss+xml" title="Juli&aacute;n Tachella &raquo; Comments Feed" href="https://tachella.github.io/comments/feed/">
<link rel="stylesheet" id="wp-block-library-css" href="https://tachella.github.io/wp-includes/css/dist/block-library/style.min.css?ver=5.6.4" type="text/css" media="all">
<link rel="stylesheet" id="gridzone-style-css" href="https://tachella.github.io/wp-content/themes/gridzone/style.css?ver=5.6.4" type="text/css" media="all">
<style id="gridzone-style-inline-css" type="text/css">
body { font-family: "Roboto", Arial, sans-serif; }

.single .post-wrapper { max-width: 1124px; }
				

.single .entry-header,
.single .entry-footer,
.single .entry > *:not(.alignfull) { max-width: 1097px; }
				

.page .post-wrapper { max-width: 1065px; }
				

.page .entry-header,
.page .entry-footer,
.page .entry > *:not(.alignfull) { max-width: 953px; }
				

.toggle-search,
#profile-image img,
.masonry-item .masonry-inner,
.masonry-item .entry-category a,
.pagination ul li a,
.post-wrapper,
.author-bio,
.sharrre-container,
.post-nav,
.comment-tabs li a,
#commentform,
.alx-tab img,
.alx-posts img,
.infinite-scroll #infinite-handle span { border-radius: 0px; }
.masonry-item img { border-radius: 0px 0px 0 0; }
.toggle-search.active,
.col-2cl .sidebar .widget { border-radius:  0px 0 0 0px; }
.search-expand,
.col-2cr .sidebar .widget { border-radius:  0 0px 0px 0; }
#footer-bottom #back-to-top { border-radius: 0 0 0px 0px; }
				
.site-title a img { max-height: 59px; }
.site-title a, .site-description { color: #353535; }

</style>
<link rel="stylesheet" id="gridzone-responsive-css" href="https://tachella.github.io/wp-content/themes/gridzone/responsive.css?ver=5.6.4" type="text/css" media="all">
<link rel="stylesheet" id="gridzone-font-awesome-css" href="https://tachella.github.io/wp-content/themes/gridzone/fonts/all.min.css?ver=5.6.4" type="text/css" media="all">
<link rel="stylesheet" id="roboto-css" href="//fonts.googleapis.com/css?family=Roboto%3A400%2C300italic%2C300%2C400italic%2C700&amp;subset=latin%2Clatin-ext&amp;ver=5.6.4" type="text/css" media="all">
<script type="text/javascript" src="https://tachella.github.io/wp-includes/js/jquery/jquery.min.js?ver=3.5.1" id="jquery-core-js"></script>
<script type="text/javascript" src="https://tachella.github.io/wp-includes/js/jquery/jquery-migrate.min.js?ver=3.3.2" id="jquery-migrate-js"></script>
<script type="text/javascript" src="https://tachella.github.io/wp-content/plugins/alx-extensions/js/jquery.sharrre.min.js?ver=1.0.1" id="alx-ext-sharrre-js"></script>
<script type="text/javascript" src="https://tachella.github.io/wp-content/themes/gridzone/js/slick.min.js?ver=5.6.4" id="gridzone-slick-js"></script>
<link rel="alternate" type="application/json" href="https://tachella.github.io/wp-json/wp/v2/posts/552">

<link rel="canonical" href="https://tachella.github.io/2021/04/16/equivariant-imaging-learning-beyond-the-range-space/">

<link rel="alternate" type="application/json+oembed" href="https://tachella.github.io/wp-json/oembed/1.0/embed?url=https%3A%2F%2Ftachella.github.io%2F2021%2F04%2F16%2Fequivariant-imaging-learning-beyond-the-range-space%2F">
<link rel="alternate" type="text/xml+oembed" href="https://tachella.github.io/wp-json/oembed/1.0/embed?url=https%3A%2F%2Ftachella.github.io%2F2021%2F04%2F16%2Fequivariant-imaging-learning-beyond-the-range-space%2F&amp;format=xml">
<style type="text/css" id="custom-background-css">
body.custom-background { background-color: #e5e5e5; }
</style>
	<link rel="icon" href="https://tachella.github.io/wp-content/uploads/2019/10/cropped-me-1-150x150.jpg" sizes="32x32">
<link rel="icon" href="https://tachella.github.io/wp-content/uploads/2019/10/cropped-me-1-200x200.jpg" sizes="192x192">
<link rel="apple-touch-icon" href="https://tachella.github.io/wp-content/uploads/2019/10/cropped-me-1-200x200.jpg">
<meta name="msapplication-TileImage" content="https://tachella.github.io/wp-content/uploads/2019/10/cropped-me-1-300x300.jpg">
<style id="kirki-inline-styles"></style></head>

<body class="post-template-default single single-post postid-552 single-format-standard custom-background col-1c full-width mobile-menu skew-active logged-out">


<a class="skip-link screen-reader-text" href="#page">Skip to content</a>

<div id="wrapper">
	
	<div id="header-sticky">
		<header id="header" class="hide-on-scroll-down">

			<div class="group">
				<p class="site-title"><a href="https://tachella.github.io/" rel="home">Juli&aacute;n Tachella</a></p>
									<p class="site-description"></p>
								
									<nav class="nav-container group" id="nav-header">
						<div class="nav-toggle"><i class="fas fa-bars"></i></div>
						<div class="nav-text"></div>
						<div class="nav-wrap container"><ul id="menu-menu" class="nav container-inner group"><li id="menu-item-313" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-313"><a href="https://tachella.github.io">Publications</a></li>
<li id="menu-item-22" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-22"><a href="https://tachella.github.io/home/">About me</a></li>
<li id="menu-item-134" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-134"><a href="https://tachella.github.io/presentations/">Presentations</a></li>
<li id="menu-item-305" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-305"><a href="https://tachella.github.io/code/">Code</a></li>
</ul></div>				
					</nav>
								
									<nav class="nav-container group" id="nav-mobile">
						<div class="nav-toggle"><i class="fas fa-bars"></i></div>
						<div class="nav-text"></div>
						<div class="nav-wrap container"><ul id="menu-menu-1" class="nav container-inner group"><li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-313"><a href="https://tachella.github.io">Publications</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-22"><a href="https://tachella.github.io/home/">About me</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-134"><a href="https://tachella.github.io/presentations/">Presentations</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-305"><a href="https://tachella.github.io/code/">Code</a></li>
</ul></div>									
					</nav>
								
			</div>
			
		</header>
	</div>
	
	<div class="sidebar s2 group">
					</div>
	
	
	<div class="container" id="page">
		<div class="container-inner">			
			<div class="main">
				<div class="main-inner group">
<div class="content">
	
			<article id="post-552" class="post-552 post type-post status-publish format-standard has-post-thumbnail hentry category-neural-networks">	
			
			<div class="post-wrapper group">
				<div class="entry-media">
									</div>
				<header class="entry-header group">
					<h1 class="entry-title">Equivariant imaging: Learning beyond the range space</h1>
					<div class="entry-meta">
						<span class="entry-date"><i class="far fa-calendar"></i>April 16, 2021</span>
												<span class="entry-author"><i class="far fa-user"></i><a href="https://tachella.github.io/author/julitakl/" title="Posts by Juli&aacute;n" rel="author">Juli&aacute;n</a></span>
						<span class="entry-category"><a href="https://tachella.github.io/category/neural-networks/" rel="category tag">neural networks</a></span>
					</div>
				</header>
				<div class="entry-content">
					<div class="entry themeform">	
						
<p><strong>Authors:</strong> D. Chen, J. Tachella and M. Davies</p>



<p><strong>Preprint: </strong><a href="https://arxiv.org/abs/2103.14756%20">https://arxiv.org/abs/2103.14756 </a></p>



<p><strong>Online codes: </strong><em>To be released soon.</em></p>



<p>Inverse problems are ubiquitous in signal and image processing. In most applications, we need to reconstruct an underlying signal $x\in\mathbb{R}^{n}$, from some measurements $y\in\mathbb{R}^{m}$, that is, invert the forward measurement process, $$y = Ax+n$$ where $n$ represents some noise and $A$ is the forward operator. Due to the ill-posed nature of $A$ (we generally have $m&lt;n$) and noise, there are multiple possible solutions $x$ for a given $y$. Fortunately, the set of plausible (natural) signals $x$ lie in a small low-dimensional set $\mathcal{X}$ of the whole of $\mathbb{R}^{n}$, so we can have a unique $x$ for a given $y$.</p>



<p>The traditional approach is to build a mathematical model to describe $\mathcal{X}$ leveraging some prior knowledge about the underlying signals (e.g. natural images can be described as piecewise smooth). However, this a hard task which is problem-dependent and it is generally a loose description of the true $\mathcal{X}$.</p>



<p>In recent years, an alternative approach is to learn inverse mapping from $y\mapsto x$ directly from training data, bypassing the need to design a prior model. Fuelled by the powerful learning bias of deep convolutional neural networks (interest readers can have a look at my <a href="https://tachella.github.io/2020/09/01/the-neural-tangent-denoiser/" data-type="post" data-id="344">previous post</a> about understanding this implicit bias), the goal is to learn a function $x=f(y)$ from training pairs $(x_i,y_i)$. The fundamental limitation of this approach is that in many real world applications we can only access $y$. Training only with the $y_i$ (enforcing measurement consistency) accounts to finding an $f$ such that $y=A f(y)$. Unfortunately this is doomed to fail, as there are infinite possible functions $f$ that can fit the measurements perfectly well! This is because any $f$ can output any value in the nullspace of $A$ and still achieve measurement consistency. In other words, this fundamental limitation is a chicken-and-egg problem:  we cannot learn to solve an inverse problem without solving it first to obtain the ground-truth training data!</p>



<p>In this paper, we show that this problem can be overcome by adding a small assumption to the underlying set of signals $\mathcal{X}$: invariance. It is well-known that most natural signals posses some kind of invariance. For example, images are generally invariant to shifts or rotations. Hence, the whole sensing process $x = (f \circ A) (x)$ is necessarily an equivariant function, that is, given a transformation $T_g$ (e.g. a shift), we have that $$T_gx = (f\circ A) (T_gx)$$. The invariance gives us information of the nullspace of A, which boils down to the following observation: $$y=Ax = AT_g x&rsquo;  = A_g x&rsquo;$$ which just relies on the fact that $x&rsquo;= T_gx$ is another valid signal. Hence we can see beyond the range space of $A$, as we have an implicit access to multiple different operators  $A_g = AT_g$ for all possible transformations $T_1,\dots,T_{G}$.  </p>



<p>We show that this invariance constraint on $(f\circ A)$ can be easily incorporated as an additional loss term when training a deep network. Our experiments show that for the computed tomography and inpaiting problems,  the equivariant learning approach (only having access to measurements $y_i$) performs as well as the fully supervised case i.e. having training pairs with ground-truth data $(x_i,y_i)$, by-passing the fundamental limitation of learning to solve inverse problems. Check the paper for more details!</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img loading="lazy" width="856" height="358" src="https://tachella.github.io/wp-content/uploads/2021/04/post_invariant-1.png" alt="" class="wp-image-630" srcset="https://tachella.github.io/wp-content/uploads/2021/04/post_invariant-1.png 856w,https://tachella.github.io/wp-content/uploads/2021/04/post_invariant-1-300x125.png 300w,https://tachella.github.io/wp-content/uploads/2021/04/post_invariant-1-768x321.png 768w,https://tachella.github.io/wp-content/uploads/2021/04/post_invariant-1-520x217.png 520w" sizes="(max-width: 856px) 100vw, 856px"><figcaption>The proposed equivariant imaging learning framework can learn the reconstruction function only using compressed samples $y_i$ and still perform as well as a fully trained network which requires ground-truth pairs $(x_i,y_i)$. On the contrary, only enforcing measurement consistency is not enough to learn the reconstruction function.</figcaption></figure></div>



<p></p>
												<div class="clear"></div>				
					</div>
				</div>
				<div class="entry-footer group">
					
										
					<div class="clear"></div>
					
										
										
						<ul class="post-nav group">
		<li class="next">
		<li class="previous"><a href="https://tachella.github.io/2021/02/20/a-sketching-framework-for-reduced-data-transfer-in-photon-counting-lidar/" rel="prev"><i class="fas fa-chevron-left"></i><strong>Previous</strong> <span>A sketching framework for reduced data transfer in photon counting lidar</span></a></li>
	</ul>

										
				</div>
			</div>

		</article>

				
</div>


				</div>
			</div>	
		</div>
	</div>
	
	<div class="clear"></div>
	
	<footer id="footer">
	
					
				
		<div id="footer-bottom">
			
			<a id="back-to-top" href="#"><i class="fas fa-angle-up"></i></a>
				
			<div class="pad group">
				
				<div class="grid one-full">
					
										
					<div id="copyright">
													<p>Copyright &copy; Juli&aacute;n Tachella 2020. Contact: first.last@ed.ac.uk</p>
											</div>
					
										
										
				</div>
							
			</div>

		</div>

	</footer>
	
</div>

<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js?ver=5.6.4" id="mathjax-js"></script>
<script type="text/javascript" src="https://tachella.github.io/wp-content/themes/gridzone/js/jquery.fitvids.js?ver=5.6.4" id="gridzone-fitvids-js"></script>
<script type="text/javascript" src="https://tachella.github.io/wp-content/themes/gridzone/js/jq-sticky-anything.min.js?ver=5.6.4" id="gridzone-jq-sticky-anything-js"></script>
<script type="text/javascript" src="https://tachella.github.io/wp-content/themes/gridzone/js/imagesloaded.pkgd.min.js?ver=5.6.4" id="gridzone-imagesloaded-js"></script>
<script type="text/javascript" src="https://tachella.github.io/wp-content/themes/gridzone/js/masonry.pkgd.min.js?ver=5.6.4" id="gridzone-masonry-js"></script>
<script type="text/javascript" src="https://tachella.github.io/wp-content/themes/gridzone/js/scripts.js?ver=5.6.4" id="gridzone-scripts-js"></script>
	<script>
	/(trident|msie)/i.test(navigator.userAgent)&&document.getElementById&&window.addEventListener&&window.addEventListener("hashchange",function(){var t,e=location.hash.substring(1);/^[A-z0-9_-]+$/.test(e)&&(t=document.getElementById(e))&&(/^(?:a|select|input|button|textarea)$/i.test(t.tagName)||(t.tabIndex=-1),t.focus())},!1);
	</script>
	</body>
</html>
