<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Julián Tachella</title>
	<atom:link href="https://tachella.github.io/feed/" rel="self" type="application/rss+xml" />
	<link>http://tachella.github.io/</link>
	<description></description>
	<lastBuildDate>Tue, 29 Oct 2019 14:38:30 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.4</generator>

<image>
	<url>https://tachella.github.io/wp-content/uploads/2019/10/cropped-me-1-150x150.jpg</url>
	<title>Julián Tachella</title>
	<link>http://tachella.github.io/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Real-time 3D reconstruction from single-photon lidar data using plug-and-play point cloud denoisers</title>
		<link>https://tachella.github.io/2019/10/29/real-time-3d-reconstruction-from-single-photon-lidar-data-using-plug-and-play-point-cloud-denoisers/</link>
				<pubDate>Tue, 29 Oct 2019 11:42:10 +0000</pubDate>
		<dc:creator><![CDATA[Julián]]></dc:creator>
				<category><![CDATA[Lidar]]></category>

		<guid isPermaLink="false">https://tachella.github.io/?p=210</guid>
				<description><![CDATA[Authors: J. Tachella, Y. Altmann, N. Mellado, R. Tobin, A. McCarthy, G. S. Buller, J-.Y. Tourneret and S. McLaughlin Journal: Preprint at Arxiv Main paper: arxiv.org/pdf/1905.06700.pdf Online codes: gitlab.com/Tachella/real-time-single-photon-lidar Abstract: Single-photon lidar has emerged as a prime candidate technology for depth imaging through challenging environments. Until now, a major limitation has been the significant amount&#46;&#46;&#46;]]></description>
								<content:encoded><![CDATA[<p><strong>Authors:</strong> J. Tachella, Y. Altmann, N. Mellado, R. Tobin, A. McCarthy, G. S. Buller, J-.Y. Tourneret and S. McLaughlin</p>
<p><strong>Journal:</strong> <em>Preprint at Arxiv</em></p>
<p><strong>Main paper:</strong> <a href="https://arxiv.org/pdf/1905.06700.pdf">arxiv.org/pdf/1905.06700.pdf</a></p>
<p><strong>Online codes: </strong><a href="https://gitlab.com/Tachella/real-time-single-photon-lidar">gitlab.com/Tachella/real-time-single-photon-lidar</a></p>
<div class="video-container"><iframe title="Real-time 3D reconstruction of complex scenes using single-photon Lidar" width="740" height="416" src="https://www.youtube.com/embed/PzCcAoypUfM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<h5>Abstract:</h5>
<p>Single-photon lidar has emerged as a prime candidate technology for depth imaging through challenging environments. Until now, a major limitation has been the significant amount of time required for the analysis of the recorded data. Here we show a new computational framework for real-time three-dimensional (3D) scene reconstruction from single-photon data. By combining statistical models with highly scalable computational tools from the computer graphics community, we demonstrate 3D reconstruction of complex outdoor scenes with processing times of the order of 20 ms, where the lidar data was acquired in broad daylight from distances up to 320 metres. The proposed method can handle an unknown number of surfaces in each pixel, allowing for target detection and imaging through cluttered scenes. This enables robust, real-time target reconstruction of complex moving scenes, paving the way for single-photon lidar at video rates for practical 3D imaging applications.</p>
]]></content:encoded>
										</item>
		<item>
		<title>Bayesian 3D Reconstruction of subsampled multispectral Lidar signals</title>
		<link>https://tachella.github.io/2019/10/01/multispectral-lidar/</link>
				<pubDate>Tue, 01 Oct 2019 11:07:29 +0000</pubDate>
		<dc:creator><![CDATA[Julián]]></dc:creator>
				<category><![CDATA[Lidar]]></category>

		<guid isPermaLink="false">https://tachella.github.io/?p=189</guid>
				<description><![CDATA[Authors: J. Tachella, Y. Altmann, M. Márquez, H. Arguello-Fuentes, J-.Y. Tourneret and S. McLaughlin Journal: IEEE Transactions on Computational Imaging Full paper: https://ieeexplore.ieee.org/document/8854866 Online codes: https://gitlab.com/Tachella/musapop Abstract: Light detection and ranging (lidar) single-photon devices capture range and intensity information from a 3D scene. This modality enables long range 3D reconstruction with high range precision and&#46;&#46;&#46;]]></description>
								<content:encoded><![CDATA[<p><strong>Authors:</strong> J. Tachella, Y. Altmann, M. Márquez, H. Arguello-Fuentes, J-.Y. Tourneret and S. McLaughlin</p>
<p><strong>Journal: </strong><em>IEEE Transactions on Computational Imaging</em></p>
<p><strong>Full paper:</strong> <a href="https://ieeexplore.ieee.org/document/8854866">https://ieeexplore.ieee.org/document/8854866</a></p>
<p><strong>Online codes: </strong><a href="https://gitlab.com/Tachella/musapop">https://gitlab.com/Tachella/musapop</a></p>
<h5>Abstract:</h5>
<p>Light detection and ranging (lidar) single-photon devices capture range and intensity information from a 3D scene. This modality enables long range 3D reconstruction with high range precision and low laser power. A multispectral single-photon lidar system provides additional spectral diversity, allowing the discrimination of different materials. However, the main drawback of such systems can be the long acquisition time needed to collect enough photons in each spectral band. In this work, we tackle this problem in two ways: first, we propose a Bayesian 3D reconstruction algorithm that is able to find multiple surfaces per pixel, using few photons, i.e., shorter acquisitions. In contrast to previous algorithms, the novel method processes the jointly all the spectral bands, obtaining better reconstructions using less photon detections. The proposed model promotes spatial correlation between neighbouring points within a given surface using spatial point processes. Secondly, we account for different spatial and spectral subsampling schemes, which reduce the total number of measurements, without significant degradation of the reconstruction performance. In this way, the total acquisition time, memory requirements and computational time can be significantly reduced. The experiments performed using both synthetic and real single-photon lidar data demonstrate the advantages of tailored sampling schemes over random alternatives. Furthermore, the proposed algorithm yields better estimates than other existing methods for multi-surface reconstruction using multispectral Lidar data.</p>
]]></content:encoded>
										</item>
		<item>
		<title>Fast surface detection in single-photon lidar waveforms</title>
		<link>https://tachella.github.io/2019/09/05/fast-surface-detection-in-single-photon-lidar-waveforms/</link>
				<pubDate>Thu, 05 Sep 2019 11:20:00 +0000</pubDate>
		<dc:creator><![CDATA[Julián]]></dc:creator>
				<category><![CDATA[Lidar]]></category>

		<guid isPermaLink="false">https://tachella.github.io/?p=194</guid>
				<description><![CDATA[Authors: J. Tachella, Y. Altmann, M. Márquez, H. Arguello-Fuentes, J-.Y. Tourneret and S. McLaughlin Conference: European Signal Processing Conference (EUSIPCO), La Coruña, Spain (2019) Full paper: https://pureapps2.hw.ac.uk/ws/portalfiles/portal/25197816/PID5986663.pdf Extension: A multi-resolution version of this method was published here. Online codes: https://gitlab.com/Tachella/lidardetection Presentation slides: EUSIPCO19 from Julián Andrés Tachella Abstract: Single-photon light detection and ranging (lidar) devices can&#46;&#46;&#46;]]></description>
								<content:encoded><![CDATA[<p><strong>Authors</strong>: J. Tachella, Y. Altmann, M. Márquez, H. Arguello-Fuentes, J-.Y. Tourneret and S. McLaughlin</p>
<p><strong>Conference:</strong> European Signal Processing Conference (EUSIPCO), La Coruña, Spain (2019)</p>
<p><strong>Full paper:</strong> <a href="https://pureapps2.hw.ac.uk/ws/portalfiles/portal/25197816/PID5986663.pdf">https://pureapps2.hw.ac.uk/ws/portalfiles/portal/25197816/PID5986663.pdf</a></p>
<p><strong>Extension: </strong>A multi-resolution version of this method was published <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11138/111380T/On-fast-object-detection-using-single-photon-lidar-data/10.1117/12.2527685.short?SSO=1">here</a>.</p>
<p><strong>Online codes: </strong><a href="https://gitlab.com/Tachella/lidardetection">https://gitlab.com/Tachella/lidardetection</a></p>
<p><strong>Presentation slides:</strong></p>
<div class="video-container"><iframe title="EUSIPCO19" src="https://www.slideshare.net/slideshow/embed_code/key/huzswkYl9Texnf" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> </p>
<div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/JulinAndrsTachella/eusipco19" title="EUSIPCO19" target="_blank">EUSIPCO19</a> </strong> from <strong><a href="https://www.slideshare.net/JulinAndrsTachella" target="_blank">Julián Andrés Tachella</a></strong> </div>
</div>
<h5>Abstract:</h5>
<p>Single-photon light detection and ranging (lidar) devices can be used to obtain range and reflectivity information from 3D scenes. However, reconstructing the 3D surfaces from the raw waveforms can be very challenging, in particular when the number of spurious background detections is large compared to the number of signal detections. In this paper, we introduce a new and fast detection algorithm, which can be used to assess the presence of objects/surfaces in each waveform, allowing only the histograms where the imaged surfaces are present to be further processed. The method is compared to state-of-the-art 3D reconstruction methods using synthetic and real single-photon data and the results illustrate its benefits for fast and robust target detection using single-photon data.</p>
]]></content:encoded>
										</item>
		<item>
		<title>3D Reconstruction using single-photon lidar data: Estimating the widths of the returns</title>
		<link>https://tachella.github.io/2019/05/05/estimating-the-widths-of-the-returns/</link>
				<pubDate>Sun, 05 May 2019 10:43:53 +0000</pubDate>
		<dc:creator><![CDATA[Julián]]></dc:creator>
				<category><![CDATA[Lidar]]></category>

		<guid isPermaLink="false">https://tachella.github.io/?p=181</guid>
				<description><![CDATA[Authors: J. Tachella, Y. Altmann, J-.Y. Tourneret and S. McLaughlin Conference: International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton, 2019. Full-text: https://ieeexplore.ieee.org/abstract/document/8683075 Short presentation: ICASSP19 from Julián Andrés Tachella Abstract: Single-photon light detection and ranging (lidar) data can be used to capture depth and intensity profiles of a 3D scene. In a general setting, the&#46;&#46;&#46;]]></description>
								<content:encoded><![CDATA[<h5>Authors:</h5>
<p>J. Tachella, Y. Altmann, J-.Y. Tourneret and S. McLaughlin</p>
<p><strong>Conference:</strong> International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton, 2019.</p>
<p><strong>Full-text:</strong> <a href="https://ieeexplore.ieee.org/abstract/document/8683075">https://ieeexplore.ieee.org/abstract/document/8683075</a></p>
<h5>Short presentation:</h5>
<div class="video-container"><iframe title="ICASSP19" src="https://www.slideshare.net/slideshow/embed_code/key/8nGrJtfx73XrqO" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> </p>
<div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/JulinAndrsTachella/icassp19" title="ICASSP19" target="_blank">ICASSP19</a> </strong> from <strong><a href="https://www.slideshare.net/JulinAndrsTachella" target="_blank">Julián Andrés Tachella</a></strong> </div>
</div>
<h5>Abstract:</h5>
<p>Single-photon light detection and ranging (lidar) data can be used to capture depth and intensity profiles of a 3D scene. In a general setting, the scenes can have an unknown number of surfaces per pixel (semi-transparent surfaces or outdoor measurements), high background noise (strong ambient illumination), can be acquired by systems with a broad instrumental response (non-parallel laser beam with respect to the target surface) and with possibly high attenuating media (underwater conditions). The existing methods generally tackle only a subset of these problems and can fail in a more general scenario. In this paper, we propose a new 3D reconstruction algorithm that can handle all the aforementioned difficulties. The novel algorithm estimates the broadening of the impulse response, considers the attenuation induced by scattering media, while allowing for multiple surfaces per pixel. A series of experiments performed in real long-range and underwater lidar datasets demonstrate the performance of the proposed method.</p>
]]></content:encoded>
										</item>
		<item>
		<title>Bayesian 3D reconstruction of complex scenes from single-photon lidar data</title>
		<link>https://tachella.github.io/2019/01/21/bayesian-3d-reconstruction-of-complex-scenes-from-single-photon-lidar-data/</link>
				<pubDate>Mon, 21 Jan 2019 17:29:26 +0000</pubDate>
		<dc:creator><![CDATA[Julián]]></dc:creator>
				<category><![CDATA[Lidar]]></category>

		<guid isPermaLink="false">https://tachella.github.io/?p=44</guid>
				<description><![CDATA[Authors: J. Tachella, Y. Altmann, X. Ren, A. McCarthy, G.S. Buller, J-.Y. Tourneret and S. McLaughlin Journal: SIAM Journal on Imaging Sciences Full paper:  https://epubs.siam.org/doi/10.1137/18M1183972 Online codes: https://gitlab.com/Tachella/Manipop Short presentation: Abstract: Light detection and ranging (Lidar) data can be used to capture the depth and intensity profile of a 3D scene. This modality relies on constructing,&#46;&#46;&#46;]]></description>
								<content:encoded><![CDATA[<p><strong>Authors:</strong> J. Tachella, Y. Altmann, X. Ren, A. McCarthy, G.S. Buller, J-.Y. Tourneret and S. McLaughlin</p>
<p><b>Journal:</b> <em>SIAM Journal on Imaging Sciences</em></p>
<p><strong>Full paper:</strong>  <a href="https://epubs.siam.org/doi/10.1137/18M1183972">https://epubs.siam.org/doi/10.1137/18M1183972</a></p>
<p><strong>Online codes:</strong> <a href="https://gitlab.com/Tachella/Manipop">https://gitlab.com/Tachella/Manipop</a></p>
<h5>Short presentation:</h5>
<div class="video-container"><iframe title="MANIPOP algorithm for 3D reconstruction of complex scenes" width="740" height="416" src="https://www.youtube.com/embed/pk0tLCCqnVk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<h5></h5>
<h5>Abstract:</h5>
<p>Light detection and ranging (Lidar) data can be used to capture the depth and intensity profile of a 3D scene. This modality relies on constructing, for each pixel, a histogram of time delays between emitted light pulses and detected photon arrivals. In a general setting, more than one surface can be observed in a single pixel. The problem of estimating the number of surfaces, their reflectivity and position becomes very challenging in the low-photon regime (which equates to short acquisition times) or relatively high background levels (i.e., strong ambient illumination). This paper presents a new approach to 3D reconstruction using single-photon, single-wavelength Lidar data, which is capable of identifying multiple surfaces in each pixel. Adopting a Bayesian approach, the 3D structure to be recovered is modelled as a marked point process and reversible jump Markov chain Monte Carlo (RJ-MCMC) moves are proposed to sample the posterior distribution of interest. In order to promote spatial correlation between points belonging to the same surface, we propose a prior that combines an area interaction process and a Strauss process. New RJ-MCMC dilation and erosion updates are presented to achieve an efficient exploration of the configuration space. To further reduce the computational load, we adopt a multiresolution approach, processing the data from a coarse to the finest scale. The experiments performed with synthetic and real data show that the algorithm obtains better reconstructions than other recently published optimization algorithms for lower execution times.</p>
]]></content:encoded>
										</item>
		<item>
		<title>Bayesian restoration of high-dimensional photon-starved images</title>
		<link>https://tachella.github.io/2018/09/10/bayesian-restoration-of-high-dimensional-photon-starved-images/</link>
				<pubDate>Mon, 10 Sep 2018 11:03:07 +0000</pubDate>
		<dc:creator><![CDATA[Julián]]></dc:creator>
				<category><![CDATA[Low-photon imaging]]></category>

		<guid isPermaLink="false">https://tachella.github.io/?p=187</guid>
				<description><![CDATA[Authors: J. Tachella, Y. Altmann, M. Pereyra, J-.Y. Tourneret and S. McLaughlin Conference: European Conference on Signal Processing (EUSIPCO), Rome, Italy, 2018. Full-text: https://ieeexplore.ieee.org/abstract/document/8553175 Codes: https://gitlab.com/Tachella/photon-starved-samplers Short presentation: Bayesian restoration of high-dimensional photon-starved images from Julián Andrés Tachella Abstract: This paper investigates different algorithms to perform image restoration from single-photon measurements corrupted with Poisson noise. The restoration&#46;&#46;&#46;]]></description>
								<content:encoded><![CDATA[<p><strong>Authors:</strong> J. Tachella, Y. Altmann, M. Pereyra, J-.Y. Tourneret and S. McLaughlin</p>
<p><strong>Conference:</strong><em> European Conference on Signal Processing (EUSIPCO), Rome, Italy, 2018.</em></p>
<p><strong>Full-text:</strong> <a href="https://ieeexplore.ieee.org/abstract/document/8553175">https://ieeexplore.ieee.org/abstract/document/8553175</a></p>
<p><strong>Codes:</strong> <a href="https://gitlab.com/Tachella/photon-starved-samplers">https://gitlab.com/Tachella/photon-starved-samplers</a></p>
<h5>Short presentation:</h5>
<div class="video-container"><iframe title="Bayesian restoration of high-dimensional photon-starved images" src="https://www.slideshare.net/slideshow/embed_code/key/pZ0Vl6NVofg15z" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> </p>
<div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/JulinAndrsTachella/bayesian-restoration-of-highdimensional-photonstarved-images" title="Bayesian restoration of high-dimensional photon-starved images" target="_blank">Bayesian restoration of high-dimensional photon-starved images</a> </strong> from <strong><a href="https://www.slideshare.net/JulinAndrsTachella" target="_blank">Julián Andrés Tachella</a></strong> </div>
</div>
<h5></h5>
<h5>Abstract:</h5>
<p>This paper investigates different algorithms to perform image restoration from single-photon measurements corrupted with Poisson noise. The restoration problem is formulated in a Bayesian framework and several state-of-the-art Monte Carlo samplers are considered to estimate the unknown image and quantify its uncertainty. The different samplers are compared through a series of experiments conducted with synthetic images. The results demonstrate the scaling properties of the proposed samplers as the dimensionality of the problem increases and the number of photons decreases. Moreover, our experiments show that for a certain photon budget (i.e., acquisition time of the imaging device), downsampling the observations can yield better reconstruction results.</p>
]]></content:encoded>
										</item>
	</channel>
</rss>
